{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ftmthb/NER/blob/main/gradio_ner_pfe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-4OCzxOIxRN"
      },
      "source": [
        "##### installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiysUWl3PFsP",
        "outputId": "181d8f2c-b3de-45ef-ac2e-064bb0caf26e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.26.6-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv)\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.16.1)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (4.3.6)\n",
            "Downloading virtualenv-20.26.6-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: distlib, virtualenv\n",
            "Successfully installed distlib-0.3.8 virtualenv-20.26.6\n"
          ]
        }
      ],
      "source": [
        "!pip install virtualenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIXjAzVKO27u",
        "outputId": "51c4e222-c31f-430c-b84c-7a8ea237c2a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "created virtual environment CPython3.10.12.final.0-64 in 2312ms\n",
            "  creator CPython3Posix(dest=/content/drive/MyDrive/virtual_env, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==24.2, setuptools==75.1.0, wheel==0.44.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
          ]
        }
      ],
      "source": [
        "!virtualenv /content/drive/MyDrive/virtual_env\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SluzN3CmPNFk",
        "outputId": "70c1b6b2-deea-4895-b89f-0d2701093e17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!source /content/drive/MyDrive/virtual_env/bin/activate; pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp6kRBLPl61n",
        "outputId": "a7051b1c-e646-4d63-8d95-9b6961afa2e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ipymarkup\n",
            "  Downloading ipymarkup-0.9.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting intervaltree>=3 (from ipymarkup)\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sortedcontainers<3.0,>=2.0 (from intervaltree>=3->ipymarkup)\n",
            "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
            "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: intervaltree\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26097 sha256=f17abf528f1a0c5f8b71ef57623ee800c8849496a2e8f3845993a56b7167e059\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n",
            "Successfully built intervaltree\n",
            "Installing collected packages: sortedcontainers, intervaltree, ipymarkup\n",
            "Successfully installed intervaltree-3.1.0 ipymarkup-0.9.0 sortedcontainers-2.4.0\n"
          ]
        }
      ],
      "source": [
        "!source /content/drive/MyDrive/virtual_env/bin/activate; pip install ipymarkup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b58rqfcJXa3g"
      },
      "source": [
        "##### env activate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RWbMHJP4Xa3-"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/virtual_env/lib/python3.10/site-packages\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK3dGMzbxwd-"
      },
      "source": [
        "#### import model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "tpLFLJnp-mnP"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifierx = pipeline('ner',r\"Fatimetou/xlm-roberta-large\",  device_map = 'auto')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eEswTbux6Qy"
      },
      "source": [
        "#### Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiChPAAdx-jM"
      },
      "source": [
        "##### id_2_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HUi3QJg3lOmV"
      },
      "outputs": [],
      "source": [
        "label_2_id = {'O': 0,\n",
        " 'B-FULL_NAME': 1,\n",
        " 'I-FULL_NAME': 2,\n",
        " 'B-CIN': 3,\n",
        " 'I-CIN': 4,\n",
        " 'B-PROPERTY_TITLE': 5,\n",
        " 'I-PROPERTY_TITLE': 6,\n",
        " 'B-PROPERTY_PRICE': 7,\n",
        " 'I-PROPERTY_PRICE': 8,\n",
        " 'B-SAVE_DATE': 9,\n",
        " 'I-SAVE_DATE': 10}\n",
        "\n",
        "label_2_id = {v: k for k, v in label_2_id.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_WRKY2TyFus"
      },
      "source": [
        "#### clean text\n",
        "from redundant characters, whitespaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vO5EvnR1if0i"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\"\"\"\n",
        "  bert handles whitespaes while roberta treats them as separate tokens, while giving them the G tokewhich also comes at the beggining of other splitted words\n",
        "\n",
        "  this function replaces all the unwanted or redundant characters with a space\n",
        "\n",
        "  it also deals with short lines and therefore\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def clean_text_data(input_text):\n",
        "\n",
        "  replacements = [\n",
        "      (r'٨{4,}', ' ',),\n",
        "      (r'\\s{2,}', ' ',),\n",
        "      (r'\\n{2,}', r'\\n',),\n",
        "      (r'\\.{2,}', ' '),\n",
        "      (r'\\={2,}', ' '),\n",
        "      (r'\\-{2,}', ' '),\n",
        "      ('x{2,}', ' '),\n",
        "      (r'\\*{2,}', ' '),\n",
        "      (r'\\xad', ' '),\n",
        "      (r'\\xa0', ' '),\n",
        "      (r'\\x80', ''),\n",
        "      (r'\\x9d', ''),\n",
        "      (r'\\x13', ' '),\n",
        "      ]\n",
        "\n",
        "  for old, new in replacements:\n",
        "      input_text = re.sub(old, new, input_text)\n",
        "\n",
        "  lines = input_text.splitlines()\n",
        "\n",
        "  lines = [re.sub(r'\\s+', ' ', line.strip()) for line in lines if line.strip()]\n",
        "\n",
        "  clean_lines = []\n",
        "  current_line = \"\"\n",
        "\n",
        "  for line in lines:\n",
        "\n",
        "      if current_line  and not current_line.endswith(('.', ':')):   #and len(current_line) + len(line) < 700\n",
        "          current_line += \" \" + line\n",
        "      else:\n",
        "          if current_line:\n",
        "              clean_lines.append(current_line)\n",
        "          current_line = line\n",
        "\n",
        "  if current_line:\n",
        "      clean_lines.append(current_line)\n",
        "\n",
        "  return \"\\n\".join(clean_lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlmqjD4eyFh_"
      },
      "source": [
        "### Split text\n",
        "\n",
        "In some cases where the given text is tokenized into over 512 tokens, it needs to be splitted into chunks  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E1vWTXVbaVh-"
      },
      "outputs": [],
      "source": [
        "def split_text(text, max_length=512):\n",
        "    if len(text) <= max_length:\n",
        "        return [(0, text)]\n",
        "\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = start + max_length\n",
        "        if end >= len(text):\n",
        "            chunks.append((start, text[start:]))\n",
        "            break\n",
        "        chunks.append((start, text[start:end]))\n",
        "        start = end\n",
        "    return chunks       #where chunk is a list of tuples with the index of the first 'string' of the chunk and the text composing it in the second position"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ejt9gHAUyWde"
      },
      "source": [
        "#### process chunk\n",
        "\n",
        "as in classify the NE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N3kAqnK3iwbs"
      },
      "outputs": [],
      "source": [
        "def process_chunk(chunk_start, chunk_text):\n",
        "    res = classifierx(chunk_text)\n",
        "\n",
        "    spans = []  #for the ipymarkup functions\n",
        "    for elt in res:\n",
        "        label = elt['entity']\n",
        "        id = int(label.split('_')[1])\n",
        "        if id != 0:\n",
        "            spans.append((\n",
        "                chunk_start + elt['start'],\n",
        "                chunk_start + elt['end'],\n",
        "                label_2_id[id]\n",
        "            ))\n",
        "    return spans    #classifies ie extracts named entities by chunk and return spans like [(pos_start, pos_end, label), ...]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyFieJxpy6rT"
      },
      "source": [
        "#### custom palette\n",
        "\n",
        "adjust the box_markup function to give different colors for each label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "e-h2j5ReikJF"
      },
      "outputs": [],
      "source": [
        "from ipymarkup import show_span_box_markup, format_span_box_markup\n",
        "\n",
        "from ipymarkup.palette import palette, Color, BLUE, RED, GREEN, ORANGE, PURPLE, BROWN\n",
        "from ipymarkup.palette import material\n",
        "\n",
        "\n",
        "TEAL = Color(\n",
        "    'teal',\n",
        "    background=material('Teal', '50'),\n",
        "    border=material('Teal', '100'),\n",
        "    text=material('Teal', '300'),\n",
        "    line=material('Teal', '200')\n",
        ")\n",
        "\n",
        "AMBER = Color(\n",
        "    'amber',\n",
        "    background=material('Amber', '50'),\n",
        "    border=material('Amber', '100'),\n",
        "    text=material('Amber', '300'),\n",
        "    line=material('Amber', '200')\n",
        ")\n",
        "\n",
        "PINK = Color(\n",
        "    'pink',\n",
        "    background=material('Pink', '50'),\n",
        "    border=material('Pink', '100'),\n",
        "    text=material('Pink', '300'),\n",
        "    line=material('Pink', '200')\n",
        ")\n",
        "\n",
        "CYAN = Color(\n",
        "    'cyan',\n",
        "    background=material('Cyan', '50'),\n",
        "    border=material('Cyan', '100'),\n",
        "    text=material('Cyan', '300'),\n",
        "    line=material('Cyan', '200')\n",
        ")\n",
        "\n",
        "YELLOW = Color(\n",
        "    'yellow',\n",
        "    background=material('Yellow', '50'),\n",
        "    border=material('Yellow', '100'),\n",
        "    text=material('Yellow', '300'),\n",
        "    line=material('Yellow', '200')\n",
        ")\n",
        "\n",
        "def get_span_box_markup(text, spans):\n",
        "    custom_palette = palette(\n",
        "        **{\n",
        "            \"B-FULL_NAME\": BLUE, \"I-FULL_NAME\": CYAN,\n",
        "            \"B-CIN\": RED, \"I-CIN\": PINK,\n",
        "            \"B-PROPERTY_TITLE\": GREEN, \"I-PROPERTY_TITLE\": TEAL,\n",
        "            \"B-PROPERTY_PRICE\": ORANGE, \"I-PROPERTY_PRICE\": YELLOW,\n",
        "            \"B-SAVE_DATE\": PURPLE, \"I-SAVE_DATE\": AMBER,\n",
        "            \"B-OWNER_NAME\": BROWN, \"I-OWNER_NAME\": BLUE,\n",
        "            \"B-PROPERTY_AREA\": CYAN, \"I-PROPERTY_AREA\": RED,\n",
        "            \"B-TRANSACTION_DATE\": TEAL, \"I-TRANSACTION_DATE\": PINK\n",
        "        }\n",
        "    )\n",
        "    return ''.join(format_span_box_markup(text, spans, palette=custom_palette))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exh11IW_zPI9"
      },
      "source": [
        "####  predict function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nK3dnvrly_Qt"
      },
      "outputs": [],
      "source": [
        "import concurrent.futures\n",
        "\n",
        "def predict(text_to_classify):\n",
        "    text_to_classify = clean_text_data(text_to_classify)\n",
        "    chunks = split_text(text_to_classify)\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:   #chunk parallel processing (time)\n",
        "        future_to_chunk = {executor.submit(process_chunk, start, text): (start, text) for start, text in chunks}\n",
        "        all_spans = []\n",
        "        for future in concurrent.futures.as_completed(future_to_chunk):\n",
        "            all_spans.extend(future.result())\n",
        "\n",
        "    # return show_span_box_markup(text_to_classify, all_spans)    #for in notebook\n",
        "\n",
        "    return get_span_box_markup(text_to_classify, all_spans)         #for interface\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### interface configuration"
      ],
      "metadata": {
        "id": "gm-zqq0A2j3K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "6uzkCuCks0PQ",
        "outputId": "8c975d2b-2bda-4527-fcc1-2590795a8d28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://e1ae8572b684a2eb50.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e1ae8572b684a2eb50.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://e1ae8572b684a2eb50.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import gradio as gr\n",
        "iface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Textbox(lines=100, label=\"Texte à classifier\"),\n",
        "    outputs=gr.HTML(label=\"Résultat\"),\n",
        "    title=\"Système de Reconnaissance des entités nommées (pour longs textes)\",\n",
        "    description=\"Entrez le texte:\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True, debug = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mkosLZXSffp5"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "iface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Textbox(lines=100, label=\"Texte à classifier\"),\n",
        "    outputs=gr.HTML(label=\"Résultat\"),\n",
        "    title=\"Système de Reconnaissance des entités nommées (pour longs textes)\",\n",
        "    description=\"Entrez le texte:\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "krNzjPkB0cSN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "a8c79fe2-fc99-495b-b323-8bcbdf58e45c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://9708544f9d15e994ed.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9708544f9d15e994ed.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://9708544f9d15e994ed.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "iface.launch(share=True, debug = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GrVNmECd3DFx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Q-4OCzxOIxRN"
      ],
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPsI58N+K0IBd3LGfqaAzX5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}